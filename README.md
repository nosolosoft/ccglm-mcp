# CCGLM MCP Server

Servidor MCP que permite usar Claude Code con backend GLM de Z.AI desde la instancia principal de Claude Code (Anthropic Sonnet).

## üéØ Prop√≥sito

Permite a Claude Code (con Sonnet de Anthropic) invocar otra instancia de Claude Code que utiliza los modelos GLM de Z.AI como backend, sin necesidad de cambiar la configuraci√≥n principal.

## üèóÔ∏è Arquitectura

```
Claude Code (Sonnet Anthropic)
    ‚Üì
MCP Tool: mcp__ccglm-mcp__glm_route
    ‚Üì
CCGLM MCP Server
    ‚Üì
Claude CLI con env vars GLM
    ‚Üì
Z.AI GLM API (https://api.z.ai/api/anthropic)
    ‚Üì
Modelo GLM-4.6
```

## üì¶ Instalaci√≥n

### 1. Instalar Dependencias

```bash
cd ~/IA/ccglm-mcp
pip install -r requirements.txt
```

### 2. Configurar Credentials

Ya est√° configurado en `.env`:

```bash
GLM_BASE_URL=https://api.z.ai/api/anthropic
GLM_AUTH_TOKEN=5951e8ffb37b4f038ba9a47f49e86ff4.ZYOeeSK1MWARJ8YB
```

### 3. Registrar Servidor MCP

A√±adir a `~/.claude/settings.json`:

```json
{
  "mcpServers": {
    "ccglm-mcp": {
      "command": "python3",
      "args": ["/home/manu/IA/ccglm-mcp/ccglm_mcp_server.py"],
      "timeout": 300000
    }
  }
}
```

### 4. Configurar Alias (Opcional)

A√±adir a `~/.zshrc`:

```bash
# Z.AI GLM Integration
export GLM_API_TOKEN="5951e8ffb37b4f038ba9a47f49e86ff4.ZYOeeSK1MWARJ8YB"
alias ccglm='ANTHROPIC_BASE_URL=https://api.z.ai/api/anthropic ANTHROPIC_AUTH_TOKEN=$GLM_API_TOKEN claude --dangerously-skip-permissions -c'
```

Recargar:
```bash
source ~/.zshrc
```

## üõ†Ô∏è Herramienta Disponible

### `glm_route`

√önica herramienta del servidor CCGLM-MCP. Enruta prompt a GLM-4.6 v√≠a Claude CLI con backend Z.AI. Maneja todos los casos de uso: generaci√≥n de c√≥digo, an√°lisis profundo y consultas generales.

**Uso desde Claude Code:**
```
Usa la herramienta mcp__ccglm-mcp__glm_route con el prompt: "Tu tarea aqu√≠"
```

**Uso con hashtag (configurado en CLAUDE.md):**
```
#ccglm Explica qu√© es recursi√≥n
#ccglm Genera una API REST en Python
#ccglm Analiza este c√≥digo en detalle
```

**Caracter√≠sticas:**
- ‚úÖ Generaci√≥n de c√≥digo con tracking de archivos
- ‚úÖ An√°lisis profundo (timeout 30 minutos)
- ‚úÖ Consultas generales
- ‚úÖ Excluye archivos internos (.claude/, .git/, etc.) del tracking

**Nota:** Usa el modelo GLM-4.6 configurado en `~/.claude/settings.json`.

## üß™ Testing

Ejecutar tests:

```bash
cd ~/IA/ccglm-mcp
python3 test_server.py
```

Tests incluidos:
- ‚úÖ File tracking (detecci√≥n de archivos creados)
- ‚úÖ Log sanitization (redacci√≥n de tokens)
- ‚è∏Ô∏è Basic prompt (comentado - requiere API call)
- ‚è∏Ô∏è Code generation (comentado - requiere API call)

## üîí Seguridad

- **Token protegido**: Almacenado en `.env` (gitignored)
- **Logs sanitizados**: Token redactado autom√°ticamente en logs
- **Environment isolation**: Variables de entorno inyectadas solo en subprocess
- **Permisos**: `.env` debe tener permisos 0600

## üìä Logging

Todos los logs van a **stderr** (no stdout) para no interferir con el protocolo MCP stdio.

**Ver logs en tiempo real:**
```bash
python3 /home/manu/IA/ccglm-mcp/ccglm_mcp_server.py 2>&1 | grep -i glm
```

**Niveles de log:**
- `INFO`: Operaciones normales
- `WARNING`: Situaciones an√≥malas
- `ERROR`: Fallos

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Timeouts

Configurados en `ccglm_mcp_server.py`:

- `DEFAULT_TIMEOUT = 600` (10 minutos)
- `MAX_TIMEOUT = 2400` (40 minutos)

### Flags de Claude CLI

El servidor ejecuta Claude CLI con:
```bash
claude --dangerously-skip-permissions -c -p
```

- `--dangerously-skip-permissions`: Skip permissions prompts
- `-c`: Continue mode
- `-p`: Print mode (non-interactive)

## üêõ Troubleshooting

### Error: "claude command not found"

Verifica que Claude CLI est√° instalado:
```bash
which claude
```

Si no est√°, instalar:
```bash
npm install -g @anthropic-ai/claude-code
```

### Error: "GLM authentication failed"

Verifica que el token en `.env` es correcto y est√° activo.

### Timeout errors

Si GLM tarda mucho, aumenta los timeouts en `ccglm_mcp_server.py`.

### No aparece en herramientas MCP

1. Verifica registro en `~/.claude/settings.json`
2. Reinicia Claude Code
3. Verifica logs: `python3 ccglm_mcp_server.py`

## üìù Uso desde Terminal

Adem√°s del servidor MCP, puedes usar GLM directamente desde terminal con el alias:

```bash
# Uso interactivo
ccglm

# Con prompt directo
echo "Explain recursion" | ccglm
```

## üîÑ Actualizaci√≥n

Para actualizar el servidor:

```bash
cd ~/IA/ccglm-mcp
git pull  # Si est√° en git
pip install -r requirements.txt --upgrade
```

Reiniciar Claude Code para recargar el servidor MCP.

## üìö Referencias

- [Documentaci√≥n Z.AI GLM](https://docs.z.ai/devpack/tool/claude)
- [MCP Protocol](https://github.com/anthropics/mcp)
- [Claude Code CLI](https://github.com/anthropics/claude-code)

## ü§ù Cr√©ditos

- Basado en patr√≥n de `ccr-mcp`
- Integraci√≥n con Z.AI GLM API
- Implementado como parte del ecosistema Claude hybrid system

## üìÑ Licencia

Uso interno - No redistribuir con credentials
